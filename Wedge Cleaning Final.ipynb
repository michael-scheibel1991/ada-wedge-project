{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wedge Cleaning Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import csv\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_files = os.listdir('ZipFiles') #It saves the directory of files called ZipFiles which is currently holding\n",
    "                                          #the uncleaned files and names it zip_files\n",
    "                                            #and make sure directory pulls up to double check\n",
    "#os.listdir('ZipFiles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of headers\n",
    "headers = [\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#make a new diretory\n",
    "#make new directory to hold extracted files\n",
    "temp_folder_name = \"wedge_clean\"\n",
    "if not os.path.isdir(temp_folder_name): #if folder exisits\n",
    "    os.mkdir(temp_folder_name)          # if not, make it\n",
    "for zip_file in zip_files : #files found in the wedge directory from the firts extraction of the large zip file\n",
    "    with ZipFile('ZipFiles/' + zip_file, 'r') as my_zip_file:#read the zip files in the directory as my_zip_file\n",
    "        files_inside = my_zip_file.namelist() #assign new name of files inside\n",
    "        for zipped_file in files_inside :\n",
    "            sniffer = csv.Sniffer()\n",
    "            with my_zip_file.open(zipped_file,'r') as input_file:\n",
    "                output_file_name = input_file.name.replace('.csv','_clean.csv')#rename new files\n",
    "                with open(\"wedge_main_clean/\" + output_file_name,'w') as outfile:#open the output file name in new folder\n",
    "                    outfile.write(\",\".join(headers) + \"\\n\") #write the files and join the headers to the new outfile\n",
    "                    rows_printed = 0\n",
    "                    for idx,line in enumerate(input_file):\n",
    "                        file_has_header = False\n",
    "                        dialect = sniffer.sniff(line.decode(\"utf-8\"))\n",
    "                        line = line.decode(\"utf-8\").strip().split(dialect.delimiter)#take a bytes object line to a normal string, strip it and then split the string to list\n",
    "                        line=[piece.replace('\"','') for piece in line] #use list comprehension to remove the double quotes\n",
    "                        line=[piece.replace(\"//N\",'') for piece in line]#remove null vaules\n",
    "                        line=[piece.replace('NULL','') for piece in line]\n",
    "                        #since we split on commas, the item \"Fruit, yogurt\" etc split into different columns\n",
    "                        #we need to combine these columns back into one\n",
    "                        if len(line) != 50: #our \"good\" columns are length 50. if > 50, we need to combine\n",
    "                            new_column = (\"\".join(line[5:8])) #make a new column by combining the ones that were split by commas\n",
    "                            #print(new_column)\n",
    "                            #now remove the bad columns\n",
    "                            #print(len(line))\n",
    "                            del(line[5:8])\n",
    "                            #print(line)\n",
    "                            #print(len(line))\n",
    "                            #insert the new fixed column\n",
    "                            line.insert(5,new_column)\n",
    "                            #print(line)\n",
    "                            #print(len(line))\n",
    "                        #if the first row has a datetime in it, then the file has a header\n",
    "                        if idx == 0:\n",
    "                            if 'datetime' in line[0]:\n",
    "                                file_has_header = True\n",
    "                        if file_has_header and idx == 0:\n",
    "                            pass #don't print the line\n",
    "                        else:\n",
    "                            outfile.write(\",\".join(line) + \"\\n\")\n",
    "                            rows_printed += 1\n",
    "print(f\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
